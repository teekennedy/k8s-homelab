# Prometheus alerting rules for I/O monitoring
# PrometheusRule is the proper CRD for Prometheus Operator to pick up alerting rules
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: io-monitoring-rules
  namespace: {{ .Release.Namespace }}
  labels:
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
  - name: io_monitoring
    interval: 60s
    rules:

    # Alert on high node-level disk I/O utilization
    - alert: HighDiskIOUtilization
      expr: rate(node_disk_io_time_seconds_total[2m]) > 0.5
      for: 5m
      labels:
        severity: warning
        component: storage
      annotations:
        summary: {{ "High disk I/O on {{ $labels.instance }}" | quote }}
        description: {{ "Disk {{ $labels.device }} on {{ $labels.instance }} has >50% I/O utilization for 5+ minutes (current: {{ $value | humanizePercentage }})" | quote }}

    # Alert on high container write I/O (per-workload)
    - alert: HighContainerWriteIO
      expr: rate(container_fs_writes_bytes_total{container!=""}[2m]) > 50000000
      for: 5m
      labels:
        severity: warning
        component: container
      annotations:
        summary: {{ "High write I/O from {{ $labels.pod }} in {{ $labels.namespace }}" | quote }}
        description: {{ "Container {{ $labels.container }} in pod {{ $labels.pod }} ({{ $labels.namespace }}) is writing >50MB/s for 5+ minutes on device {{ $labels.device }} (current: {{ $value | humanize }}B/s)" | quote }}

    # Alert on high disk queue depth (weighted IO time = avg queue depth)
    - alert: HighDiskQueueDepth
      expr: rate(node_disk_io_time_weighted_seconds_total[2m]) > 2
      for: 3m
      labels:
        severity: warning
        component: storage
      annotations:
        summary: {{ "High disk queue depth on {{ $labels.instance }}" | quote }}
        description: {{ "Disk {{ $labels.device }} on {{ $labels.instance }} avg queue depth >2 for 3+ min (current: {{ $value }})" | quote }}

    # Alert on high average disk latency (>20ms per IO operation)
    - alert: HighDiskLatency
      expr: |
        (rate(node_disk_read_time_seconds_total[2m]) + rate(node_disk_write_time_seconds_total[2m]))
        / (rate(node_disk_reads_completed_total[2m]) + rate(node_disk_writes_completed_total[2m])) > 0.02
      for: 3m
      labels:
        severity: warning
        component: storage
      annotations:
        summary: {{ "High disk latency on {{ $labels.instance }}" | quote }}
        description: {{ "Avg IO latency >20ms on {{ $labels.device }} ({{ $labels.instance }})" | quote }}

    # Alert on PostgreSQL checkpoint duration
    - alert: PostgreSQLSlowCheckpoint
      expr: increase(pg_stat_bgwriter_checkpoint_write_time[5m]) / increase(pg_stat_bgwriter_checkpoints_timed[5m]) > 15000
      for: 2m
      labels:
        severity: info
        component: postgres
      annotations:
        summary: {{ "Slow PostgreSQL checkpoint on {{ $labels.instance }}" | quote }}
        description: {{ "PostgreSQL checkpoints are taking >15 seconds on average (current: {{ $value | humanizeDuration }})" | quote }}
